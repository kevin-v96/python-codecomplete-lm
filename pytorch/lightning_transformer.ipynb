{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtcBqCPzA-h2",
    "outputId": "de804980-b73a-4c64-a6dc-b5f2bf2a72cc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting lightning\n",
      "  Downloading lightning-2.2.4-py3-none-any.whl.metadata (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.4/53.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb\n",
      "  Downloading wandb-0.16.6-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.3)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting tqdm>=4.62.1 (from datasets)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.2.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Collecting lightning-utilities<2.0,>=0.8.0 (from lightning)\n",
      "  Downloading lightning_utilities-0.11.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: torch<4.0,>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (2.2.0)\n",
      "Collecting torchmetrics<3.0,>=0.7.0 (from lightning)\n",
      "  Downloading torchmetrics-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from lightning) (4.9.0)\n",
      "Collecting pytorch-lightning (from lightning)\n",
      "  Downloading pytorch_lightning-2.2.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting Click!=8.0.0,>=7.1 (from wandb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
      "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.8)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.1.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (69.0.3)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting protobuf!=4.21.0,<5,>=3.19.0 (from wandb)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch<4.0,>=1.13.0->lightning) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<4.0,>=1.13.0->lightning) (12.3.101)\n",
      "Collecting pretty-errors==1.2.25 (from torchmetrics<3.0,>=0.7.0->lightning)\n",
      "  Downloading pretty_errors-1.2.25-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting colorama (from pretty-errors==1.2.25->torchmetrics<3.0,>=0.7.0->lightning)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
      "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<4.0,>=1.13.0->lightning) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<4.0,>=1.13.0->lightning) (1.3.0)\n",
      "Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning-2.2.4-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
      "Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.4.28-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.1/774.1 kB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sentry_sdk-2.1.0-py2.py3-none-any.whl (277 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.1/277.1 kB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.4.0-py3-none-any.whl (868 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pretty_errors-1.2.25-py3-none-any.whl (17 kB)\n",
      "Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m145.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Downloading pytorch_lightning-2.2.4-py3-none-any.whl (802 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m91.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pytz, appdirs, xxhash, tzdata, tqdm, smmap, setproctitle, sentry-sdk, regex, pyarrow-hotfix, pyarrow, protobuf, multidict, lightning-utilities, frozenlist, docker-pycreds, dill, colorama, Click, async-timeout, yarl, tiktoken, pretty-errors, pandas, multiprocess, huggingface-hub, gitdb, aiosignal, GitPython, aiohttp, wandb, torchmetrics, pytorch-lightning, datasets, lightning\n",
      "Successfully installed Click-8.1.7 GitPython-3.1.43 aiohttp-3.9.5 aiosignal-1.3.1 appdirs-1.4.4 async-timeout-4.0.3 colorama-0.4.6 datasets-2.19.1 dill-0.3.8 docker-pycreds-0.4.0 frozenlist-1.4.1 gitdb-4.0.11 huggingface-hub-0.23.0 lightning-2.2.4 lightning-utilities-0.11.2 multidict-6.0.5 multiprocess-0.70.16 pandas-2.2.2 pretty-errors-1.2.25 protobuf-4.25.3 pyarrow-16.0.0 pyarrow-hotfix-0.6 pytorch-lightning-2.2.4 pytz-2024.1 regex-2024.4.28 sentry-sdk-2.1.0 setproctitle-1.3.3 smmap-5.0.1 tiktoken-0.6.0 torchmetrics-1.4.0 tqdm-4.66.4 tzdata-2024.1 wandb-0.16.6 xxhash-3.4.1 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tiktoken datasets lightning wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkevinv3796\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-egsolkTCl_u"
   },
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lightning as L\n",
    "from typing import Any\n",
    "from torch.utils.data import random_split\n",
    "import os\n",
    "import pickle\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "import wandb\n",
    "import torch\n",
    "import numpy as np\n",
    "def get_device():\n",
    "    return torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "class TokenEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch module that converts tokens into embeddings.\n",
    "\n",
    "    Input dimension is: (batch_size, sequence_length)\n",
    "    Output dimension is: (batch_size, sequence_length, d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, number_of_tokens):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = torch.nn.Embedding(\n",
    "            num_embeddings=number_of_tokens,\n",
    "            embedding_dim=d_model\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding_layer(x)\n",
    "\n",
    "\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module that creates a positional encoding matrix. This matrix will later be added to the\n",
    "    transformer's input embeddings to provide a sense of position of the sequence elements.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, max_sequence_length):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.positional_encoding = self.create_positional_encoding()\n",
    "\n",
    "    def create_positional_encoding(self):\n",
    "        \"\"\"\n",
    "        Creates a positional encoding matrix of size (max_sequence_length, d_model).\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize positional encoding matrix\n",
    "        positional_encoding = np.zeros((self.max_sequence_length, self.d_model))\n",
    "\n",
    "        # Calculate positional encoding for each position and each dimension\n",
    "        for pos in range(self.max_sequence_length):\n",
    "            for i in range(0, self.d_model, 2):\n",
    "                # Apply sin to even indices in the array; indices in Python start at 0 so i is even.\n",
    "                positional_encoding[pos, i] = np.sin(pos / (10000 ** ((2 * i) / self.d_model)))\n",
    "\n",
    "                if i + 1 < self.d_model:\n",
    "                    # Apply cos to odd indices in the array; we add 1 to i because indices in Python start at 0.\n",
    "                    positional_encoding[pos, i + 1] = np.cos(pos / (10000 ** ((2 * i) / self.d_model)))\n",
    "\n",
    "        # Convert numpy array to PyTorch tensor and return it\n",
    "        return torch.from_numpy(positional_encoding).float().to(get_device())\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Adds the positional encoding to the input embeddings at the corresponding positions.\n",
    "        \"\"\"\n",
    "        # Add positional encodings to input embeddings. The \":\" indexing ensures we only add positional encodings up\n",
    "        # to the length of the sequence in the batch. x.size(0) is the batch size, so this is a way to make sure\n",
    "        # we're not adding extra positional encodings.\n",
    "        positional_encoding = self.positional_encoding[:x.size(1), :]\n",
    "        return x + positional_encoding\n",
    "\n",
    "\n",
    "class MaskedSelfAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for a self attention layer.\n",
    "    This layer is used in the MultiHeadedSelfAttention module.\n",
    "\n",
    "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    Output dimension is: (batch_size, sequence_length, head_dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dimension, head_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.head_dimension = head_dimension\n",
    "        self.query_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
    "        self.key_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
    "        self.value_layer = torch.nn.Linear(embedding_dimension, self.head_dimension)\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Compute the self attention.\n",
    "\n",
    "        x dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "        output dimension is: (batch_size, sequence_length, head_dimension)\n",
    "        mask dimension is: (batch_size, sequence_length)\n",
    "\n",
    "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
    "        \"\"\"\n",
    "\n",
    "        # x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        # query, key, value dimensions are: (batch_size, sequence_length, head_dimension)\n",
    "        query = self.query_layer(x)\n",
    "        key = self.key_layer(x)\n",
    "        value = self.value_layer(x)\n",
    "\n",
    "        # Calculate the attention weights.\n",
    "        # attention_weights dimensions are: (batch_size, sequence_length, sequence_length)\n",
    "        attention_weights = torch.matmul(query, key.transpose(-2, -1))\n",
    "\n",
    "        # Scale the attention weights.\n",
    "        attention_weights = attention_weights / np.sqrt(self.head_dimension)\n",
    "\n",
    "        # Apply the mask to the attention weights, by setting the masked tokens to a very low value.\n",
    "        # This will make the softmax output 0 for these values.\n",
    "        mask = mask.reshape(attention_weights.shape[0], 1, attention_weights.shape[2])\n",
    "        _MASKING_VALUE = -1e+30 if attention_weights.dtype == torch.float32 else -1e+4\n",
    "        #https://discuss.pytorch.org/t/runtimeerror-value-cannot-be-converted-to-type-at-half-without-overflow-1e-30/109768\n",
    "        attention_weights = attention_weights.masked_fill(mask == 0, _MASKING_VALUE)\n",
    "\n",
    "        # Softmax makes sure all scores are between 0 and 1 and the sum of scores is 1.\n",
    "        # attention_scores dimensions are: (batch_size, sequence_length, sequence_length)\n",
    "        attention_scores = self.softmax(attention_weights)\n",
    "\n",
    "        # The attention scores are multiplied by the value\n",
    "        # Values of tokens with high attention score get highlighted because they are multiplied by a larger number,\n",
    "        # and tokens with low attention score get drowned out because they are multiplied by a smaller number.\n",
    "        # Output dimensions are: (batch_size, sequence_length, head_dimension)\n",
    "        return torch.bmm(attention_scores, value)\n",
    "\n",
    "\n",
    "class MaskedMultiHeadedSelfAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for a multi head attention layer.\n",
    "\n",
    "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    Output dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dimension, number_of_heads):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.head_dimension = embedding_dimension // number_of_heads\n",
    "        self.number_of_heads = number_of_heads\n",
    "\n",
    "        # Create the self attention modules\n",
    "        self.self_attentions = torch.nn.ModuleList(\n",
    "            [MaskedSelfAttention(embedding_dimension, self.head_dimension) for _ in range(number_of_heads)])\n",
    "\n",
    "        # Create a linear layer to combine the outputs of the self attention modules\n",
    "        self.output_layer = torch.nn.Linear(number_of_heads * self.head_dimension, embedding_dimension)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Compute the multi head attention.\n",
    "\n",
    "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        mask dimensions are: (batch_size, sequence_length)\n",
    "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
    "        \"\"\"\n",
    "        # Compute the self attention for each head\n",
    "        # self_attention_outputs dimensions are:\n",
    "        # (number_of_heads, batch_size, sequence_length, head_dimension)\n",
    "        self_attention_outputs = [self_attention(x, mask) for self_attention in self.self_attentions]\n",
    "\n",
    "        # Concatenate the self attention outputs\n",
    "        # self_attention_outputs_concatenated dimensions are:\n",
    "        # (batch_size, sequence_length, number_of_heads * head_dimension)\n",
    "        concatenated_self_attention_outputs = torch.cat(self_attention_outputs, dim=2)\n",
    "\n",
    "        # Apply the output layer to the concatenated self attention outputs\n",
    "        # output dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        return self.output_layer(concatenated_self_attention_outputs)\n",
    "\n",
    "\n",
    "class FeedForward(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for a feed forward layer.\n",
    "\n",
    "    A feed forward layer is a fully connected layer with a ReLU activation function in between.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dimension, feed_forward_dimension):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.feed_forward_dimension = feed_forward_dimension\n",
    "        self.linear_1 = torch.nn.Linear(embedding_dimension, feed_forward_dimension)\n",
    "        self.linear_2 = torch.nn.Linear(feed_forward_dimension, embedding_dimension)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Compute the feed forward layer.\n",
    "        \"\"\"\n",
    "        return self.linear_2(torch.relu(self.linear_1(x)))\n",
    "\n",
    "\n",
    "class DecoderLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for an encoder layer.\n",
    "\n",
    "    An encoder layer consists of a multi-headed self attention layer, a feed forward layer and dropout.\n",
    "\n",
    "    Input dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    Output dimension is: (batch_size, sequence_length, embedding_dimension)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dimension,\n",
    "            number_of_heads,\n",
    "            feed_forward_dimension,\n",
    "            dropout_rate\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.number_of_heads = number_of_heads\n",
    "        self.feed_forward_dimension = feed_forward_dimension\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.multi_headed_self_attention = MaskedMultiHeadedSelfAttention(embedding_dimension, number_of_heads)\n",
    "        self.feed_forward = FeedForward(embedding_dimension, feed_forward_dimension)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.layer_normalization_1 = torch.nn.LayerNorm(embedding_dimension)\n",
    "        self.layer_normalization_2 = torch.nn.LayerNorm(embedding_dimension)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Compute the encoder layer.\n",
    "\n",
    "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        mask dimensions are: (batch_size, sequence_length)\n",
    "        mask values are: 0 or 1. 0 means the token is masked, 1 means the token is not masked.\n",
    "        \"\"\"\n",
    "\n",
    "        # Layer normalization 1\n",
    "        normalized_x = self.layer_normalization_1(x)\n",
    "\n",
    "        # Multi headed self attention\n",
    "        attention_output = self.multi_headed_self_attention(normalized_x, mask)\n",
    "\n",
    "        # Residual output\n",
    "        residual_output = x + attention_output\n",
    "\n",
    "        # Layer normalization 2\n",
    "        normalized_residual_output = self.layer_normalization_2(residual_output)\n",
    "\n",
    "        # Feed forward\n",
    "        feed_forward_output = self.feed_forward(normalized_residual_output)\n",
    "\n",
    "        # Dropout\n",
    "        if self.training:\n",
    "            feed_forward_output = self.dropout(feed_forward_output)\n",
    "\n",
    "        # Residual output\n",
    "        return residual_output + feed_forward_output\n",
    "\n",
    "\n",
    "class DecoderStack(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The decoder stack consists of multiple decoder layers in sequence.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            embedding_dimension,\n",
    "            number_of_layers,\n",
    "            number_of_heads,\n",
    "            feed_forward_dimension,\n",
    "            dropout_rate,\n",
    "            max_sequence_length\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.number_of_layers = number_of_layers\n",
    "        self.number_of_heads = number_of_heads\n",
    "        self.feed_forward_dimension = feed_forward_dimension\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "\n",
    "        # Create the encoder layers\n",
    "        self.encoder_layers = torch.nn.ModuleList(\n",
    "            [DecoderLayer(embedding_dimension, number_of_heads, feed_forward_dimension, dropout_rate) for _ in\n",
    "             range(number_of_layers)])\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        decoder_outputs = x\n",
    "        for decoder_layer in self.encoder_layers:\n",
    "            decoder_outputs = decoder_layer(decoder_outputs, mask)\n",
    "\n",
    "        return decoder_outputs\n",
    "\n",
    "\n",
    "class LMHead(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for the language model head.\n",
    "    The language model head is a linear layer that maps the embedding dimension to the vocabulary size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_dimension, number_of_tokens):\n",
    "        super().__init__()\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.number_of_tokens = number_of_tokens\n",
    "        self.linear = torch.nn.Linear(embedding_dimension, number_of_tokens)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Compute the language model head.\n",
    "\n",
    "        x dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        output dimensions are: (batch_size, sequence_length, number_of_tokens)\n",
    "        \"\"\"\n",
    "        # Compute the linear layer\n",
    "        # linear_output dimensions are: (batch_size, sequence_length, number_of_tokens)\n",
    "        linear_output = self.linear(x)\n",
    "\n",
    "        return linear_output\n",
    "\n",
    "\n",
    "class LanguageModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module for a language model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            number_of_tokens,  # The number of tokens in the vocabulary\n",
    "            max_sequence_length=512,  # The maximum sequence length to use for attention\n",
    "            embedding_dimension=512,  # The dimension of the token embeddings\n",
    "            number_of_layers=6,  # The number of decoder layers to use\n",
    "            number_of_heads=4,  # The number of attention heads to use\n",
    "            feed_forward_dimension=None,  # The dimension of the feed forward layer\n",
    "            dropout_rate=0.1  # The dropout rate to use\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.number_of_tokens = number_of_tokens\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding_dimension = embedding_dimension\n",
    "        self.number_of_layers = number_of_layers\n",
    "        self.number_of_heads = number_of_heads\n",
    "\n",
    "        if feed_forward_dimension is None:\n",
    "            # GPT-2 paper uses 4 * embedding_dimension for the feed forward dimension\n",
    "            self.feed_forward_dimension = embedding_dimension * 4\n",
    "        else:\n",
    "            self.feed_forward_dimension = feed_forward_dimension\n",
    "\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Create the token embedding layer\n",
    "        self.token_embedding = TokenEmbedding(embedding_dimension, number_of_tokens)\n",
    "\n",
    "        # Create the positional encoding layer\n",
    "        self.positional_encoding = PositionalEncoding(embedding_dimension, max_sequence_length)\n",
    "\n",
    "        # Create the normalization layer\n",
    "        self.layer_normalization = torch.nn.LayerNorm(embedding_dimension)\n",
    "\n",
    "        # Create the decoder stack\n",
    "        self.decoder = DecoderStack(\n",
    "            embedding_dimension=embedding_dimension,\n",
    "            number_of_layers=number_of_layers,\n",
    "            number_of_heads=number_of_heads,\n",
    "            feed_forward_dimension=self.feed_forward_dimension,\n",
    "            dropout_rate=dropout_rate,\n",
    "            max_sequence_length=max_sequence_length\n",
    "        )\n",
    "\n",
    "        # Create the language model head\n",
    "        self.lm_head = LMHead(embedding_dimension, number_of_tokens)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        # Compute the token embeddings\n",
    "        # token_embeddings dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        token_embeddings = self.token_embedding(x)\n",
    "\n",
    "        # Compute the positional encoding\n",
    "        # positional_encoding dimensions are: (batch_size, sequence_length, embedding_dimension)\n",
    "        positional_encoding = self.positional_encoding(token_embeddings)\n",
    "\n",
    "        # Post embedding layer normalization\n",
    "        positional_encoding_normalized = self.layer_normalization(positional_encoding)\n",
    "\n",
    "        decoder_outputs = self.decoder(positional_encoding_normalized, mask)\n",
    "        lm_head_outputs = self.lm_head(decoder_outputs)\n",
    "\n",
    "        return lm_head_outputs\n",
    "\n",
    "\n",
    "class AutoregressiveWrapper(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Pytorch module that wraps a GPT model and makes it autoregressive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, gpt_model):\n",
    "        super().__init__()\n",
    "        self.model = gpt_model\n",
    "        self.max_sequence_length = self.model.max_sequence_length\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"\"\"\n",
    "        Autoregressive forward pass\n",
    "        \"\"\"\n",
    "        #x.shape, mask.shape = (batch_size, sequence_length)\n",
    "        inp, target = x[:, :-1], x[:, 1:]\n",
    "        mask = mask[:, :-1]\n",
    "\n",
    "        #inp.shape, mask.shape = (batch_size, sequence length - 1 (see above))\n",
    "        output = self.model(inp, mask)\n",
    "        return output, target\n",
    "\n",
    "    def next_token_probabilities(self, x, mask, temperature=1.0):\n",
    "        \"\"\"\n",
    "        Calculate the token probabilities for the next token in the sequence.\n",
    "        \"\"\"\n",
    "        logits = self.model(x, mask)[:, -1]\n",
    "\n",
    "        # Apply temperature\n",
    "        if temperature != 1.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "        # Apply the softmax\n",
    "        probabilities = torch.softmax(logits, dim=-1)\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "class LitGPT(L.LightningModule):\n",
    "    def __init__(self, autoregressive_model, config, *args: Any, **kwargs: Any) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        #self.example_input_array = torch.Tensor(32, 1, 28, 28)  # need to change this\n",
    "        self.model = autoregressive_model\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        for (\n",
    "            key,\n",
    "            value,\n",
    "        ) in (\n",
    "            config.__dict__.items()\n",
    "        ):  # this assigns all of the config in this format: self.lr = config.lr\n",
    "            setattr(self, key, value)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def evaluate_batch_loss(self, batch):\n",
    "        input_ids, attention_mask = batch\n",
    "        outputs, targets = self.model(x=input_ids, mask=attention_mask)\n",
    "        # Reshape targets to match the format expected by CrossEntropyLoss\n",
    "        targets_flat = targets.reshape(-1)  # Flatten to shape [batch_size * sequence_length]\n",
    "        # Flatten logits to shape [batch_size * sequence_length, num_classes]\n",
    "        outputs_flat = outputs.reshape(-1, outputs.shape[2])\n",
    "        # Compute loss\n",
    "        loss = self.loss_function(outputs_flat, targets_flat)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        train_loss = self.evaluate_batch_loss(batch)\n",
    "        self.log(\"train/loss\", train_loss)\n",
    "        return train_loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        val_loss = self.evaluate_batch_loss(batch)\n",
    "        self.log(\"val/loss\", val_loss)\n",
    "        return val_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    def forward(self, x, mask, *args: Any, **kwargs: Any) -> Any:\n",
    "        print('x shape:', x.shape, 'mask shape:', mask.shape)\n",
    "        pred = self.model(x, mask)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Pl3u83O2IV6n"
   },
   "outputs": [],
   "source": [
    "class CodeSnippetDataset(Dataset):\n",
    "    def __init__(self, snippets, tokenizer):\n",
    "        self.snippets = snippets\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.snippets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        snippet = self.snippets[idx]\n",
    "\n",
    "        # Tokenize the snippet\n",
    "        input_ids = self.tokenizer.encode(snippet, allowed_special=\"all\")\n",
    "        attention_mask = [1] * len(input_ids)  # Assume all tokens are attended to\n",
    "\n",
    "        return input_ids, attention_mask\n",
    "\n",
    "class PyCodeDataModule(L.LightningDataModule):\n",
    "    def __init__(self, tokenizer, config, data_dir: str = os.getcwd()):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.tokenizer = tokenizer\n",
    "        self.vocab = tokenizer.n_vocab\n",
    "        for (\n",
    "            key,\n",
    "            value,\n",
    "        ) in (\n",
    "            config.__dict__.items()\n",
    "        ):  # this assigns all of the config in this format: self.lr = config.lr\n",
    "            setattr(self, key, value)\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        \"\"\"\n",
    "        Prepares the data by downloading and tokenizing it. Runs once, on Rank 0.\n",
    "        \"\"\"\n",
    "        raw_data = load_dataset(\n",
    "            \"ArtifactAI/arxiv_python_research_code\",\n",
    "            split=f\"train[:{self.total_samples}]\",\n",
    "        )\n",
    "        torch_data = raw_data.with_format(\"torch\")\n",
    "        tokenized_dataset = CodeSnippetDataset(torch_data[\"code\"], self.tokenizer)\n",
    "        # lighting recommends you save to disk and load in the setup function to be compatible with distributed training\n",
    "        with open(\"saved_dataset.pkl\", \"wb\") as f:\n",
    "            pickle.dump(tokenized_dataset, f)\n",
    "\n",
    "    def collate_fn(self, batch, max_length):\n",
    "        \"\"\"Collate function for dataloader\"\"\"\n",
    "        input_ids_list, attention_mask_list = [], []\n",
    "\n",
    "        # Process each snippet in the batch\n",
    "        for input_ids, attention_mask in batch:\n",
    "            # Truncate input_ids and attention_mask based on the maximum sequence length in the batch\n",
    "            input_ids = input_ids[:max_length]\n",
    "            attention_mask = attention_mask[:max_length]\n",
    "\n",
    "            # Pad input_ids and attention_mask to max_length\n",
    "            padding_length = max_length - len(input_ids)\n",
    "            padded_input_ids = input_ids + [self.padding_token_id] * padding_length\n",
    "            padded_attention_mask = attention_mask + [0] * padding_length\n",
    "\n",
    "            input_ids_list.append(padded_input_ids)\n",
    "            attention_mask_list.append(padded_attention_mask)\n",
    "\n",
    "        # Convert lists to tensors\n",
    "        input_ids_tensor = torch.tensor(input_ids_list, dtype=torch.long)\n",
    "        attention_mask_tensor = torch.tensor(attention_mask_list, dtype=torch.long)\n",
    "\n",
    "        return input_ids_tensor, attention_mask_tensor\n",
    "\n",
    "    def setup(self, stage: str) -> None:\n",
    "        # load the dataset from disk\n",
    "        # dataset = load_dataset_from_disk(...)\n",
    "        # Assign train/val datasets for use in dataloaders\n",
    "        with open(\"saved_dataset.pkl\", \"rb\") as f:\n",
    "            tokenized_dataset = pickle.load(f)\n",
    "        valid_size = self.valid_size\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset, self.val_dataset = random_split(\n",
    "                tokenized_dataset,\n",
    "                [1 - valid_size, valid_size],\n",
    "                generator=torch.Generator().manual_seed(42),\n",
    "            )\n",
    "\n",
    "        if stage == \"test\":\n",
    "            pass\n",
    "\n",
    "        if stage == \"predict\":\n",
    "            pass\n",
    "\n",
    "    def train_dataloader(self) -> Any:\n",
    "        return DataLoader(\n",
    "            self.train_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            collate_fn=lambda batch: self.collate_fn(batch, max_length = self.max_length),\n",
    "            num_workers=95\n",
    "        )  # the batch size needs to be self.batch_size for tuner to work\n",
    "\n",
    "    def val_dataloader(self) -> Any:\n",
    "        return DataLoader(\n",
    "            self.val_dataset, \n",
    "            batch_size=self.batch_size, \n",
    "            collate_fn=lambda batch: self.collate_fn(batch, max_length = self.max_length),\n",
    "            num_workers=95\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eas75dytE-Cn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/lightning/pytorch/utilities/parsing.py:199: Attribute 'autoregressive_model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['autoregressive_model'])`.\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "#wandb.init()\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")\n",
    "eos_token_id = enc.eot_token\n",
    "eos_token = enc.decode([eos_token_id])\n",
    "config = SimpleNamespace(\n",
    "        total_samples = 10000,\n",
    "        valid_size = 0.2,\n",
    "        batch_size = 32,\n",
    "        max_length = 512,\n",
    "        epochs=100,\n",
    "        learning_rate=4e-2,\n",
    "        max_grad_norm = 0.5,\n",
    "        embedding_dimension = 256,\n",
    "        number_of_heads=4,\n",
    "        number_of_layers=3,\n",
    "        dropout_rate=0.1,\n",
    "        padding_token_id = eos_token_id,\n",
    "        padding_token = eos_token,\n",
    "    )\n",
    "\n",
    "\n",
    "litgpt = LitGPT(\n",
    "    autoregressive_model=AutoregressiveWrapper(\n",
    "        LanguageModel(\n",
    "            embedding_dimension=config.embedding_dimension,\n",
    "            number_of_tokens=enc.n_vocab,\n",
    "            number_of_heads=config.number_of_heads,\n",
    "            number_of_layers=config.number_of_layers,\n",
    "            dropout_rate=config.dropout_rate,\n",
    "            max_sequence_length=config.max_length,\n",
    "        )\n",
    "    ),\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "dm = PyCodeDataModule(tokenizer=enc, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hbB-FnaVUqUi"
   },
   "outputs": [],
   "source": [
    "#Callbacks\n",
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "from lightning.pytorch.callbacks import ModelSummary, DeviceStatsMonitor, ModelCheckpoint, StochasticWeightAveraging, ModelPruning\n",
    "\n",
    "swa_cb = StochasticWeightAveraging(swa_lrs=1e-2, swa_epoch_start=75) # results in smoother loss landscape and not getting stuck on local minimas, optional\n",
    "earlystopping_cb = EarlyStopping(monitor='val/loss', mode='min')\n",
    "model_summary_cb = ModelSummary(max_depth=-1) #this does not usually need to be set unless you want to modify behaviour\n",
    "pruning_cb = ModelPruning(\"l1_unstructured\", amount=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408,
     "referenced_widgets": [
      "7eeed4f420ea4d7ea8bb75c1f8cc20be",
      "2dcf5b137bf9429da393a22ba44a0690",
      "28038860cade426280e6357e725fddaf",
      "d51b79395f8d40cbb9e629537d1d8b39",
      "266fe7f780be46b7b7a786f45fc52f03",
      "031f1eaa29104b169f5605519bc35a56",
      "eaf9670975bd45429ef727106f9acda7",
      "6e3a71b390ad46c2bbd49c2f3d882306",
      "cad62726d05748468c76aa2bddfa7a9f",
      "93da4a3f85a946b79cdedbda5c249c5c",
      "351c18f3a6b14e8c9ca9d1a13a54eea4",
      "bb7f9592305f4a7bbfd823062d10035b",
      "ff5b94d367154134b9d51904d29e2645",
      "f5f765b836894fb690176eb06af88df3",
      "1edddea06e354c859c693099fc59869a",
      "211f72f39bd147c1b0e0758f312ac785",
      "a081923d643541c2b8ebe5aeb1d3f5f7",
      "85897537871842abae7f77446a3e758e",
      "11255d5ac026403cab1f185d67171372",
      "03c00cb5f379473babd75bb9ec2ce777",
      "88ed8bdd6b7445fd98f3dbf26694f2cb",
      "1a8218a010264caf813f82ad6ec81d80",
      "fa672fcdd4fa4c1f843277f3aa546f03",
      "a457643427714397bcc326d75170d3eb",
      "b61aadb89e5f489ea5584476311aa1bf",
      "c33a18b4ec65446cb616ef6021856d99",
      "65617058a05a488c85cbcb2f121379b7",
      "ebee14caddbe4a73ac00fbbf55ffc949",
      "4736c709597142deb9dbebe94fc8958f",
      "7de96955858d4aaaad54572761ddad06",
      "41e85561fee74f0d852384eb79f7c047",
      "b694f36cae4c4763a8a88322c0ad1fd0",
      "4b9e87ed45054537aab741f0d0a96063",
      "27c38b6b0cdf4bd9bd7534d697f310bd",
      "5069ebe6fa2f4183b0f135b46cad903c",
      "9d3b56e986dd46c9bfc934c027623eb8",
      "eb3232379f0f4cd1809f03864298e17e",
      "d1b1db4883b9425885566349b3bfb771",
      "9b0145647cf24b4fbda5bf3b793851f3",
      "9125d7bfdaeb44d09b85edcae2ca2ac7",
      "0ac6cb191c33445a9a500e76446b7440",
      "5f91dc80894d4f3e9f8c8f3a46a19843",
      "8fc4f8eaebd2499bbb89f88e2808bd88",
      "6afcd33eed0144cd8b4b1bf31a034f09"
     ]
    },
    "id": "f9k9asQjE3cR",
    "outputId": "8d407c73-a58a-44b8-d63f-330bf8b62ed8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.model_summary.ModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "wandb_logger = WandbLogger(project=\"transformer-lightning\")\n",
    "trainer = L.Trainer(\n",
    "    profiler=\"simple\",\n",
    "    logger=wandb_logger,\n",
    "    accelerator=\"auto\",\n",
    "    devices=\"auto\",\n",
    "    strategy=\"auto\",\n",
    "    precision=\"16-mixed\",  # 32-true by default. Other options: bf16-mixed, 16-true, 64-true (high memory, more sensitive)\n",
    "    gradient_clip_val=0.5,  # default 0,\n",
    "    #fast_dev_run=True, #turn this off after debugging model and data modules code\n",
    "    max_epochs=config.epochs,\n",
    "    callbacks = [\n",
    "        model_summary_cb,\n",
    "        swa_cb,\n",
    "        earlystopping_cb,\n",
    "        pruning_cb\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tuner = Tuner(trainer)\n",
    "#tuner.scale_batch_size(litgpt, datamodule = dm, mode = \"binsearch\") result = 58, using 32 because of cuda out of memory errors\n",
    "#tuner.lr_find(litgpt, datamodule = dm) #result = 0.003981071705534969, using 4e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LVcMlTaNGjzw"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6d32ef3b80c4a0ea2da45c46c781924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20240506_114005-hul59r2g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kevinv3796/transformer-lightning/runs/hul59r2g' target=\"_blank\">treasured-grass-4</a></strong> to <a href='https://wandb.ai/kevinv3796/transformer-lightning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kevinv3796/transformer-lightning' target=\"_blank\">https://wandb.ai/kevinv3796/transformer-lightning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kevinv3796/transformer-lightning/runs/hul59r2g' target=\"_blank\">https://wandb.ai/kevinv3796/transformer-lightning/runs/hul59r2g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "    | Name                                                                                           | Type                           | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0   | model                                                                                          | AutoregressiveWrapper          | 53.8 M\n",
      "1   | model.model                                                                                    | LanguageModel                  | 53.8 M\n",
      "2   | model.model.token_embedding                                                                    | TokenEmbedding                 | 25.7 M\n",
      "3   | model.model.token_embedding.embedding_layer                                                    | Embedding                      | 25.7 M\n",
      "4   | model.model.positional_encoding                                                                | PositionalEncoding             | 0     \n",
      "5   | model.model.layer_normalization                                                                | LayerNorm                      | 512   \n",
      "6   | model.model.decoder                                                                            | DecoderStack                   | 2.4 M \n",
      "7   | model.model.decoder.encoder_layers                                                             | ModuleList                     | 2.4 M \n",
      "8   | model.model.decoder.encoder_layers.0                                                           | DecoderLayer                   | 789 K \n",
      "9   | model.model.decoder.encoder_layers.0.multi_headed_self_attention                               | MaskedMultiHeadedSelfAttention | 263 K \n",
      "10  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions               | ModuleList                     | 197 K \n",
      "11  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.0             | MaskedSelfAttention            | 49.3 K\n",
      "12  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.0.query_layer | Linear                         | 16.4 K\n",
      "13  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.0.key_layer   | Linear                         | 16.4 K\n",
      "14  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.0.value_layer | Linear                         | 16.4 K\n",
      "15  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.0.softmax     | Softmax                        | 0     \n",
      "16  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.1             | MaskedSelfAttention            | 49.3 K\n",
      "17  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.1.query_layer | Linear                         | 16.4 K\n",
      "18  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.1.key_layer   | Linear                         | 16.4 K\n",
      "19  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.1.value_layer | Linear                         | 16.4 K\n",
      "20  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.1.softmax     | Softmax                        | 0     \n",
      "21  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.2             | MaskedSelfAttention            | 49.3 K\n",
      "22  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.2.query_layer | Linear                         | 16.4 K\n",
      "23  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.2.key_layer   | Linear                         | 16.4 K\n",
      "24  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.2.value_layer | Linear                         | 16.4 K\n",
      "25  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.2.softmax     | Softmax                        | 0     \n",
      "26  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.3             | MaskedSelfAttention            | 49.3 K\n",
      "27  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.3.query_layer | Linear                         | 16.4 K\n",
      "28  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.3.key_layer   | Linear                         | 16.4 K\n",
      "29  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.3.value_layer | Linear                         | 16.4 K\n",
      "30  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.self_attentions.3.softmax     | Softmax                        | 0     \n",
      "31  | model.model.decoder.encoder_layers.0.multi_headed_self_attention.output_layer                  | Linear                         | 65.8 K\n",
      "32  | model.model.decoder.encoder_layers.0.feed_forward                                              | FeedForward                    | 525 K \n",
      "33  | model.model.decoder.encoder_layers.0.feed_forward.linear_1                                     | Linear                         | 263 K \n",
      "34  | model.model.decoder.encoder_layers.0.feed_forward.linear_2                                     | Linear                         | 262 K \n",
      "35  | model.model.decoder.encoder_layers.0.dropout                                                   | Dropout                        | 0     \n",
      "36  | model.model.decoder.encoder_layers.0.layer_normalization_1                                     | LayerNorm                      | 512   \n",
      "37  | model.model.decoder.encoder_layers.0.layer_normalization_2                                     | LayerNorm                      | 512   \n",
      "38  | model.model.decoder.encoder_layers.1                                                           | DecoderLayer                   | 789 K \n",
      "39  | model.model.decoder.encoder_layers.1.multi_headed_self_attention                               | MaskedMultiHeadedSelfAttention | 263 K \n",
      "40  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions               | ModuleList                     | 197 K \n",
      "41  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.0             | MaskedSelfAttention            | 49.3 K\n",
      "42  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.0.query_layer | Linear                         | 16.4 K\n",
      "43  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.0.key_layer   | Linear                         | 16.4 K\n",
      "44  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.0.value_layer | Linear                         | 16.4 K\n",
      "45  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.0.softmax     | Softmax                        | 0     \n",
      "46  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.1             | MaskedSelfAttention            | 49.3 K\n",
      "47  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.1.query_layer | Linear                         | 16.4 K\n",
      "48  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.1.key_layer   | Linear                         | 16.4 K\n",
      "49  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.1.value_layer | Linear                         | 16.4 K\n",
      "50  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.1.softmax     | Softmax                        | 0     \n",
      "51  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.2             | MaskedSelfAttention            | 49.3 K\n",
      "52  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.2.query_layer | Linear                         | 16.4 K\n",
      "53  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.2.key_layer   | Linear                         | 16.4 K\n",
      "54  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.2.value_layer | Linear                         | 16.4 K\n",
      "55  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.2.softmax     | Softmax                        | 0     \n",
      "56  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.3             | MaskedSelfAttention            | 49.3 K\n",
      "57  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.3.query_layer | Linear                         | 16.4 K\n",
      "58  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.3.key_layer   | Linear                         | 16.4 K\n",
      "59  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.3.value_layer | Linear                         | 16.4 K\n",
      "60  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.self_attentions.3.softmax     | Softmax                        | 0     \n",
      "61  | model.model.decoder.encoder_layers.1.multi_headed_self_attention.output_layer                  | Linear                         | 65.8 K\n",
      "62  | model.model.decoder.encoder_layers.1.feed_forward                                              | FeedForward                    | 525 K \n",
      "63  | model.model.decoder.encoder_layers.1.feed_forward.linear_1                                     | Linear                         | 263 K \n",
      "64  | model.model.decoder.encoder_layers.1.feed_forward.linear_2                                     | Linear                         | 262 K \n",
      "65  | model.model.decoder.encoder_layers.1.dropout                                                   | Dropout                        | 0     \n",
      "66  | model.model.decoder.encoder_layers.1.layer_normalization_1                                     | LayerNorm                      | 512   \n",
      "67  | model.model.decoder.encoder_layers.1.layer_normalization_2                                     | LayerNorm                      | 512   \n",
      "68  | model.model.decoder.encoder_layers.2                                                           | DecoderLayer                   | 789 K \n",
      "69  | model.model.decoder.encoder_layers.2.multi_headed_self_attention                               | MaskedMultiHeadedSelfAttention | 263 K \n",
      "70  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions               | ModuleList                     | 197 K \n",
      "71  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.0             | MaskedSelfAttention            | 49.3 K\n",
      "72  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.0.query_layer | Linear                         | 16.4 K\n",
      "73  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.0.key_layer   | Linear                         | 16.4 K\n",
      "74  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.0.value_layer | Linear                         | 16.4 K\n",
      "75  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.0.softmax     | Softmax                        | 0     \n",
      "76  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.1             | MaskedSelfAttention            | 49.3 K\n",
      "77  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.1.query_layer | Linear                         | 16.4 K\n",
      "78  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.1.key_layer   | Linear                         | 16.4 K\n",
      "79  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.1.value_layer | Linear                         | 16.4 K\n",
      "80  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.1.softmax     | Softmax                        | 0     \n",
      "81  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.2             | MaskedSelfAttention            | 49.3 K\n",
      "82  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.2.query_layer | Linear                         | 16.4 K\n",
      "83  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.2.key_layer   | Linear                         | 16.4 K\n",
      "84  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.2.value_layer | Linear                         | 16.4 K\n",
      "85  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.2.softmax     | Softmax                        | 0     \n",
      "86  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.3             | MaskedSelfAttention            | 49.3 K\n",
      "87  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.3.query_layer | Linear                         | 16.4 K\n",
      "88  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.3.key_layer   | Linear                         | 16.4 K\n",
      "89  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.3.value_layer | Linear                         | 16.4 K\n",
      "90  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.self_attentions.3.softmax     | Softmax                        | 0     \n",
      "91  | model.model.decoder.encoder_layers.2.multi_headed_self_attention.output_layer                  | Linear                         | 65.8 K\n",
      "92  | model.model.decoder.encoder_layers.2.feed_forward                                              | FeedForward                    | 525 K \n",
      "93  | model.model.decoder.encoder_layers.2.feed_forward.linear_1                                     | Linear                         | 263 K \n",
      "94  | model.model.decoder.encoder_layers.2.feed_forward.linear_2                                     | Linear                         | 262 K \n",
      "95  | model.model.decoder.encoder_layers.2.dropout                                                   | Dropout                        | 0     \n",
      "96  | model.model.decoder.encoder_layers.2.layer_normalization_1                                     | LayerNorm                      | 512   \n",
      "97  | model.model.decoder.encoder_layers.2.layer_normalization_2                                     | LayerNorm                      | 512   \n",
      "98  | model.model.lm_head                                                                            | LMHead                         | 25.8 M\n",
      "99  | model.model.lm_head.linear                                                                     | Linear                         | 25.8 M\n",
      "100 | loss_function                                                                                  | CrossEntropyLoss               | 0     \n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "53.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "53.8 M    Total params\n",
      "215.248   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab05529146f341308766b111c8bfed97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FIT Profiler Report\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                         \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                          \t|  -              \t|  14950          \t|  122.18         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                             \t|  65.527         \t|  1              \t|  65.527         \t|  53.632         \t|\n",
      "|  run_training_batch                                                                                                                                             \t|  0.17491        \t|  250            \t|  43.728         \t|  35.791         \t|\n",
      "|  [LightningModule]LitGPT.optimizer_step                                                                                                                         \t|  0.17447        \t|  250            \t|  43.618         \t|  35.701         \t|\n",
      "|  [LightningDataModule]PyCodeDataModule.prepare_data                                                                                                             \t|  13.418         \t|  1              \t|  13.418         \t|  10.982         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                        \t|  0.022324       \t|  250            \t|  5.5809         \t|  4.5679         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  4.6919         \t|  1              \t|  4.6919         \t|  3.8402         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                 \t|  0.010797       \t|  315            \t|  3.4011         \t|  2.7837         \t|\n",
      "|  [LightningModule]LitGPT.transfer_batch_to_device                                                                                                               \t|  0.010694       \t|  315            \t|  3.3687         \t|  2.7572         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                   \t|  0.012465       \t|  250            \t|  3.1164         \t|  2.5507         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                 \t|  0.023317       \t|  65             \t|  1.5156         \t|  1.2405         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                     \t|  0.0045983      \t|  250            \t|  1.1496         \t|  0.94091        \t|\n",
      "|  [Callback]StochasticWeightAveraging.setup                                                                                                                      \t|  0.98922        \t|  1              \t|  0.98922        \t|  0.80966        \t|\n",
      "|  [Callback]ModelPruning.setup                                                                                                                                   \t|  0.6127         \t|  1              \t|  0.6127         \t|  0.50149        \t|\n",
      "|  [LightningModule]LitGPT.configure_gradient_clipping                                                                                                            \t|  0.002059       \t|  250            \t|  0.51476        \t|  0.42132        \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                     \t|  0.0078876      \t|  65             \t|  0.51269        \t|  0.41963        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                   \t|  0.0017314      \t|  250            \t|  0.43285        \t|  0.35428        \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                       \t|  0.4048         \t|  1              \t|  0.4048         \t|  0.33132        \t|\n",
      "|  [Callback]ModelPruning.on_save_checkpoint                                                                                                                      \t|  0.20295        \t|  1              \t|  0.20295        \t|  0.16612        \t|\n",
      "|  [LightningModule]LitGPT.optimizer_zero_grad                                                                                                                    \t|  0.00049818     \t|  250            \t|  0.12455        \t|  0.10194        \t|\n",
      "|  [Callback]ModelPruning.on_train_epoch_end                                                                                                                      \t|  0.12353        \t|  1              \t|  0.12353        \t|  0.10111        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                            \t|  0.0015419      \t|  65             \t|  0.10023        \t|  0.082033       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.081012       \t|  1              \t|  0.081012       \t|  0.066307       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                              \t|  0.0010768      \t|  65             \t|  0.069993       \t|  0.057288       \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                  \t|  0.020616       \t|  2              \t|  0.041232       \t|  0.033748       \t|\n",
      "|  [LightningDataModule]PyCodeDataModule.setup                                                                                                                    \t|  0.038038       \t|  1              \t|  0.038038       \t|  0.031134       \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                            \t|  0.015361       \t|  1              \t|  0.015361       \t|  0.012573       \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                \t|  0.014227       \t|  1              \t|  0.014227       \t|  0.011644       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  3.5501e-05     \t|  250            \t|  0.0088753      \t|  0.0072643      \t|\n",
      "|  [Callback]ModelPruning.on_train_end                                                                                                                            \t|  0.0058804      \t|  1              \t|  0.0058804      \t|  0.004813       \t|\n",
      "|  [LightningModule]LitGPT.on_validation_model_eval                                                                                                               \t|  0.0013875      \t|  2              \t|  0.0027749      \t|  0.0022713      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                    \t|  0.0013586      \t|  2              \t|  0.0027171      \t|  0.0022239      \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                       \t|  9.5163e-06     \t|  250            \t|  0.0023791      \t|  0.0019472      \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                \t|  8.2043e-06     \t|  250            \t|  0.0020511      \t|  0.0016788      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_train_epoch_end                                                                               \t|  0.0016437      \t|  1              \t|  0.0016437      \t|  0.0013453      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                   \t|  0.0013956      \t|  1              \t|  0.0013956      \t|  0.0011423      \t|\n",
      "|  [LightningModule]LitGPT.on_validation_model_zero_grad                                                                                                          \t|  0.0013422      \t|  1              \t|  0.0013422      \t|  0.0010986      \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_after_backward                                                                                                          \t|  4.7258e-06     \t|  250            \t|  0.0011815      \t|  0.000967       \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                         \t|  0.0011285      \t|  1              \t|  0.0011285      \t|  0.00092367     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                 \t|  0.001105       \t|  1              \t|  0.001105       \t|  0.00090442     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_before_optimizer_step                                                                                                   \t|  4.344e-06      \t|  250            \t|  0.001086       \t|  0.00088887     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                      \t|  4.339e-06      \t|  250            \t|  0.0010848      \t|  0.00088786     \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                     \t|  4.3272e-06     \t|  250            \t|  0.0010818      \t|  0.00088543     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_before_optimizer_step                                                                         \t|  4.2658e-06     \t|  250            \t|  0.0010664      \t|  0.00087287     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  4.0447e-06     \t|  250            \t|  0.0010112      \t|  0.00082762     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                             \t|  4.0438e-06     \t|  250            \t|  0.001011       \t|  0.00082745     \t|\n",
      "|  [Callback]ModelPruning.on_after_backward                                                                                                                       \t|  4.0372e-06     \t|  250            \t|  0.0010093      \t|  0.00082609     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_after_backward                                                                                \t|  3.923e-06      \t|  250            \t|  0.00098076     \t|  0.00080274     \t|\n",
      "|  [LightningModule]LitGPT.configure_optimizers                                                                                                                   \t|  0.0009779      \t|  1              \t|  0.0009779      \t|  0.0008004      \t|\n",
      "|  [Callback]ModelPruning.on_before_optimizer_step                                                                                                                \t|  3.8442e-06     \t|  250            \t|  0.00096106     \t|  0.00078661     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  3.7253e-06     \t|  250            \t|  0.00093133     \t|  0.00076228     \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                    \t|  3.5884e-06     \t|  250            \t|  0.00089709     \t|  0.00073425     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                    \t|  3.5833e-06     \t|  250            \t|  0.00089582     \t|  0.00073322     \t|\n",
      "|  [LightningModule]LitGPT.on_after_backward                                                                                                                      \t|  3.3866e-06     \t|  250            \t|  0.00084665     \t|  0.00069297     \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                      \t|  3.3223e-06     \t|  250            \t|  0.00083057     \t|  0.00067981     \t|\n",
      "|  [LightningModule]LitGPT.on_before_optimizer_step                                                                                                               \t|  3.2585e-06     \t|  250            \t|  0.00081463     \t|  0.00066676     \t|\n",
      "|  [LightningDataModule]PyCodeDataModule.val_dataloader                                                                                                           \t|  0.00072129     \t|  1              \t|  0.00072129     \t|  0.00059036     \t|\n",
      "|  [LightningModule]LitGPT.on_before_batch_transfer                                                                                                               \t|  2.2382e-06     \t|  315            \t|  0.00070503     \t|  0.00057706     \t|\n",
      "|  [LightningModule]LitGPT.on_after_batch_transfer                                                                                                                \t|  2.0188e-06     \t|  315            \t|  0.00063591     \t|  0.00052049     \t|\n",
      "|  [LightningDataModule]PyCodeDataModule.train_dataloader                                                                                                         \t|  0.00052255     \t|  1              \t|  0.00052255     \t|  0.0004277      \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_train_batch_end                                                                                                         \t|  2.05e-06       \t|  250            \t|  0.00051251     \t|  0.00041948     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_before_zero_grad                                                                                                        \t|  2.0266e-06     \t|  250            \t|  0.00050665     \t|  0.00041468     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_train_batch_start                                                                                                       \t|  1.9361e-06     \t|  250            \t|  0.00048402     \t|  0.00039617     \t|\n",
      "|  [LightningModule]LitGPT.on_train_batch_end                                                                                                                     \t|  1.8655e-06     \t|  250            \t|  0.00046638     \t|  0.00038173     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_before_backward                                                                               \t|  1.8627e-06     \t|  250            \t|  0.00046567     \t|  0.00038114     \t|\n",
      "|  [Callback]ModelPruning.on_train_batch_start                                                                                                                    \t|  1.8385e-06     \t|  250            \t|  0.00045962     \t|  0.00037619     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_before_backward                                                                                                         \t|  1.8193e-06     \t|  250            \t|  0.00045482     \t|  0.00037227     \t|\n",
      "|  [Callback]ModelPruning.on_train_batch_end                                                                                                                      \t|  1.7816e-06     \t|  250            \t|  0.00044541     \t|  0.00036456     \t|\n",
      "|  [LightningModule]LitGPT.on_before_zero_grad                                                                                                                    \t|  1.7342e-06     \t|  250            \t|  0.00043354     \t|  0.00035485     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_train_batch_start                                                                             \t|  1.7332e-06     \t|  250            \t|  0.00043331     \t|  0.00035465     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                  \t|  1.7309e-06     \t|  250            \t|  0.00043272     \t|  0.00035418     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_before_zero_grad                                                                              \t|  1.713e-06      \t|  250            \t|  0.00042824     \t|  0.00035051     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                   \t|  1.684e-06      \t|  250            \t|  0.000421       \t|  0.00034458     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  1.6817e-06     \t|  250            \t|  0.00042043     \t|  0.00034412     \t|\n",
      "|  [LightningModule]LitGPT.on_train_batch_start                                                                                                                   \t|  1.6739e-06     \t|  250            \t|  0.00041847     \t|  0.00034251     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                 \t|  1.6492e-06     \t|  250            \t|  0.00041229     \t|  0.00033746     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_train_batch_end                                                                               \t|  1.62e-06       \t|  250            \t|  0.00040501     \t|  0.00033149     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  1.616e-06      \t|  250            \t|  0.000404       \t|  0.00033067     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  1.6008e-06     \t|  250            \t|  0.00040021     \t|  0.00032757     \t|\n",
      "|  [LightningModule]LitGPT.on_before_backward                                                                                                                     \t|  1.5507e-06     \t|  250            \t|  0.00038767     \t|  0.0003173      \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                            \t|  1.5445e-06     \t|  250            \t|  0.00038613     \t|  0.00031604     \t|\n",
      "|  [Callback]ModelPruning.on_before_zero_grad                                                                                                                     \t|  1.5369e-06     \t|  250            \t|  0.00038422     \t|  0.00031448     \t|\n",
      "|  [Callback]ModelPruning.on_before_backward                                                                                                                      \t|  1.53e-06       \t|  250            \t|  0.0003825      \t|  0.00031307     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_train_end                                                                                                               \t|  0.00038097     \t|  1              \t|  0.00038097     \t|  0.00031182     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_train_epoch_start                                                                                                       \t|  0.00035392     \t|  1              \t|  0.00035392     \t|  0.00028968     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  4.9491e-06     \t|  65             \t|  0.00032169     \t|  0.0002633      \t|\n",
      "|  [LightningModule]LitGPT.on_train_epoch_end                                                                                                                     \t|  0.00030291     \t|  1              \t|  0.00030291     \t|  0.00024792     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                 \t|  4.4225e-06     \t|  65             \t|  0.00028746     \t|  0.00023528     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_fit_start                                                                                                               \t|  0.00025389     \t|  1              \t|  0.00025389     \t|  0.00020781     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                               \t|  3.2536e-06     \t|  65             \t|  0.00021148     \t|  0.0001731      \t|\n",
      "|  [LightningModule]LitGPT.on_validation_batch_end                                                                                                                \t|  2.7157e-06     \t|  65             \t|  0.00017652     \t|  0.00014448     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  2.1604e-06     \t|  65             \t|  0.00014042     \t|  0.00011494     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_validation_batch_start                                                                                                  \t|  2.0997e-06     \t|  65             \t|  0.00013648     \t|  0.00011171     \t|\n",
      "|  [Callback]ModelPruning.on_validation_batch_start                                                                                                               \t|  2.0098e-06     \t|  65             \t|  0.00013064     \t|  0.00010692     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  6.4976e-05     \t|  2              \t|  0.00012995     \t|  0.00010636     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_validation_batch_end                                                                          \t|  1.9022e-06     \t|  65             \t|  0.00012364     \t|  0.0001012      \t|\n",
      "|  [LightningModule]LitGPT.on_validation_batch_start                                                                                                              \t|  1.8404e-06     \t|  65             \t|  0.00011962     \t|  9.7911e-05     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_validation_batch_end                                                                                                    \t|  1.7716e-06     \t|  65             \t|  0.00011515     \t|  9.4251e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_validation_batch_start                                                                        \t|  1.7625e-06     \t|  65             \t|  0.00011457     \t|  9.377e-05      \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                       \t|  5.1078e-05     \t|  2              \t|  0.00010216     \t|  8.3614e-05     \t|\n",
      "|  [Callback]ModelPruning.on_validation_batch_end                                                                                                                 \t|  1.5181e-06     \t|  65             \t|  9.8679e-05     \t|  8.0767e-05     \t|\n",
      "|  [LightningModule]LitGPT.on_validation_epoch_end                                                                                                                \t|  4.2318e-05     \t|  2              \t|  8.4637e-05     \t|  6.9274e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_validation_end                                                                                \t|  2.0106e-05     \t|  2              \t|  4.0213e-05     \t|  3.2913e-05     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.setup                                                                                            \t|  3.4999e-05     \t|  1              \t|  3.4999e-05     \t|  2.8646e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                     \t|  1.297e-05      \t|  2              \t|  2.5939e-05     \t|  2.1231e-05     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                          \t|  2.4972e-05     \t|  1              \t|  2.4972e-05     \t|  2.044e-05      \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                              \t|  2.3469e-05     \t|  1              \t|  2.3469e-05     \t|  1.9209e-05     \t|\n",
      "|  [LightningModule]LitGPT.prepare_data                                                                                                                           \t|  2.0975e-05     \t|  1              \t|  2.0975e-05     \t|  1.7168e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                               \t|  1.0244e-05     \t|  2              \t|  2.0487e-05     \t|  1.6768e-05     \t|\n",
      "|  [LightningModule]LitGPT.setup                                                                                                                                  \t|  1.9716e-05     \t|  1              \t|  1.9716e-05     \t|  1.6137e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                \t|  1.9068e-05     \t|  1              \t|  1.9068e-05     \t|  1.5607e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                               \t|  8.7116e-06     \t|  2              \t|  1.7423e-05     \t|  1.4261e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  1.7297e-05     \t|  1              \t|  1.7297e-05     \t|  1.4157e-05     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_train_epoch_end                                                                                                         \t|  1.6868e-05     \t|  1              \t|  1.6868e-05     \t|  1.3806e-05     \t|\n",
      "|  [Callback]ModelPruning.on_validation_epoch_end                                                                                                                 \t|  8.1547e-06     \t|  2              \t|  1.6309e-05     \t|  1.3349e-05     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                             \t|  7.4981e-06     \t|  2              \t|  1.4996e-05     \t|  1.2274e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  6.9309e-06     \t|  2              \t|  1.3862e-05     \t|  1.1346e-05     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                   \t|  1.199e-05      \t|  1              \t|  1.199e-05      \t|  9.8135e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_validation_start                                                                                                        \t|  4.6398e-06     \t|  2              \t|  9.2797e-06     \t|  7.5953e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                            \t|  9.1922e-06     \t|  1              \t|  9.1922e-06     \t|  7.5236e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  8.6483e-06     \t|  1              \t|  8.6483e-06     \t|  7.0785e-06     \t|\n",
      "|  [LightningDataModule]PyCodeDataModule.teardown                                                                                                                 \t|  8.3409e-06     \t|  1              \t|  8.3409e-06     \t|  6.8269e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_train_start                                                                                                                         \t|  7.702e-06      \t|  1              \t|  7.702e-06      \t|  6.304e-06      \t|\n",
      "|  [LightningDataModule]PyCodeDataModule.state_dict                                                                                                               \t|  7.5549e-06     \t|  1              \t|  7.5549e-06     \t|  6.1836e-06     \t|\n",
      "|  [Callback]ModelPruning.on_validation_start                                                                                                                     \t|  3.6769e-06     \t|  2              \t|  7.3537e-06     \t|  6.0189e-06     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                 \t|  3.607e-06      \t|  2              \t|  7.214e-06      \t|  5.9046e-06     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                   \t|  6.916e-06      \t|  1              \t|  6.916e-06      \t|  5.6606e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_validation_start                                                                              \t|  3.4189e-06     \t|  2              \t|  6.8378e-06     \t|  5.5966e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_validation_epoch_start                                                                        \t|  3.3919e-06     \t|  2              \t|  6.7838e-06     \t|  5.5524e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                  \t|  6.7819e-06     \t|  1              \t|  6.7819e-06     \t|  5.5509e-06     \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                \t|  6.7111e-06     \t|  1              \t|  6.7111e-06     \t|  5.4929e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  3.1944e-06     \t|  2              \t|  6.3889e-06     \t|  5.2292e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_validation_epoch_start                                                                                                  \t|  3.1469e-06     \t|  2              \t|  6.2939e-06     \t|  5.1514e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_fit_end                                                                                                                 \t|  6.2529e-06     \t|  1              \t|  6.2529e-06     \t|  5.1179e-06     \t|\n",
      "|  [Callback]ModelPruning.on_validation_epoch_start                                                                                                               \t|  2.9728e-06     \t|  2              \t|  5.9456e-06     \t|  4.8664e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                            \t|  2.9281e-06     \t|  2              \t|  5.8562e-06     \t|  4.7932e-06     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                   \t|  5.7071e-06     \t|  1              \t|  5.7071e-06     \t|  4.6712e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  5.4836e-06     \t|  1              \t|  5.4836e-06     \t|  4.4883e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.teardown                                                                                                                   \t|  5.167e-06      \t|  1              \t|  5.167e-06      \t|  4.2291e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  5.139e-06      \t|  1              \t|  5.139e-06      \t|  4.2062e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_validation_start                                                                                                                    \t|  2.5509e-06     \t|  2              \t|  5.1018e-06     \t|  4.1757e-06     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                     \t|  5.0198e-06     \t|  1              \t|  5.0198e-06     \t|  4.1087e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_train_epoch_start                                                                                                                   \t|  4.9286e-06     \t|  1              \t|  4.9286e-06     \t|  4.034e-06      \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_fit_end                                                                                       \t|  4.9248e-06     \t|  1              \t|  4.9248e-06     \t|  4.0309e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_fit_end                                                                                                                             \t|  4.895e-06      \t|  1              \t|  4.895e-06      \t|  4.0065e-06     \t|\n",
      "|  [Callback]ModelPruning.teardown                                                                                                                                \t|  4.8652e-06     \t|  1              \t|  4.8652e-06     \t|  3.9821e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.teardown                                                                                         \t|  4.8578e-06     \t|  1              \t|  4.8578e-06     \t|  3.976e-06      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  4.7199e-06     \t|  1              \t|  4.7199e-06     \t|  3.8632e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  4.5281e-06     \t|  1              \t|  4.5281e-06     \t|  3.7062e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                  \t|  4.502e-06      \t|  1              \t|  4.502e-06      \t|  3.6848e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                             \t|  4.4666e-06     \t|  1              \t|  4.4666e-06     \t|  3.6559e-06     \t|\n",
      "|  [Callback]ModelPruning.on_fit_end                                                                                                                              \t|  4.2357e-06     \t|  1              \t|  4.2357e-06     \t|  3.4668e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_validation_epoch_start                                                                                                              \t|  2.0238e-06     \t|  2              \t|  4.0475e-06     \t|  3.3128e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                           \t|  4.0289e-06     \t|  1              \t|  4.0289e-06     \t|  3.2976e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_train_end                                                                                                                           \t|  3.9935e-06     \t|  1              \t|  3.9935e-06     \t|  3.2686e-06     \t|\n",
      "|  [LightningModule]LitGPT.configure_callbacks                                                                                                                    \t|  3.9078e-06     \t|  1              \t|  3.9078e-06     \t|  3.1985e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                      \t|  3.6657e-06     \t|  1              \t|  3.6657e-06     \t|  3.0003e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  3.593e-06      \t|  1              \t|  3.593e-06      \t|  2.9409e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_validation_epoch_end                                                                                                    \t|  1.7956e-06     \t|  2              \t|  3.5912e-06     \t|  2.9393e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_train_start                                                                                                             \t|  3.5148e-06     \t|  1              \t|  3.5148e-06     \t|  2.8768e-06     \t|\n",
      "|  [LightningModule]LitGPT.teardown                                                                                                                               \t|  3.5018e-06     \t|  1              \t|  3.5018e-06     \t|  2.8661e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_validation_end                                                                                                          \t|  1.6978e-06     \t|  2              \t|  3.3956e-06     \t|  2.7793e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_validation_end                                                                                                                      \t|  1.6643e-06     \t|  2              \t|  3.3285e-06     \t|  2.7244e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_validation_epoch_end                                                                          \t|  1.5786e-06     \t|  2              \t|  3.1572e-06     \t|  2.5841e-06     \t|\n",
      "|  [Callback]ModelPruning.on_validation_end                                                                                                                       \t|  1.5227e-06     \t|  2              \t|  3.0454e-06     \t|  2.4926e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                              \t|  1.5218e-06     \t|  2              \t|  3.0436e-06     \t|  2.4911e-06     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                      \t|  3.0361e-06     \t|  1              \t|  3.0361e-06     \t|  2.485e-06      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  1.4929e-06     \t|  2              \t|  2.9858e-06     \t|  2.4438e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                    \t|  2.6543e-06     \t|  1              \t|  2.6543e-06     \t|  2.1725e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                    \t|  2.6245e-06     \t|  1              \t|  2.6245e-06     \t|  2.1481e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_train_end                                                                                     \t|  2.604e-06      \t|  1              \t|  2.604e-06      \t|  2.1313e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_train_epoch_start                                                                             \t|  2.4904e-06     \t|  1              \t|  2.4904e-06     \t|  2.0383e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_train_start                                                                                   \t|  2.3209e-06     \t|  1              \t|  2.3209e-06     \t|  1.8996e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_fit_start                                                                                     \t|  2.2817e-06     \t|  1              \t|  2.2817e-06     \t|  1.8676e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_fit_start                                                                                                                           \t|  2.2072e-06     \t|  1              \t|  2.2072e-06     \t|  1.8066e-06     \t|\n",
      "|  [LightningModule]LitGPT.on_save_checkpoint                                                                                                                     \t|  2.1644e-06     \t|  1              \t|  2.1644e-06     \t|  1.7715e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_save_checkpoint                                                                               \t|  2.1402e-06     \t|  1              \t|  2.1402e-06     \t|  1.7517e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_sanity_check_start                                                                                                      \t|  2.1104e-06     \t|  1              \t|  2.1104e-06     \t|  1.7273e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_save_checkpoint                                                                                                         \t|  1.9576e-06     \t|  1              \t|  1.9576e-06     \t|  1.6023e-06     \t|\n",
      "|  [Callback]ModelPruning.on_train_start                                                                                                                          \t|  1.9427e-06     \t|  1              \t|  1.9427e-06     \t|  1.5901e-06     \t|\n",
      "|  [Callback]StochasticWeightAveraging.on_sanity_check_end                                                                                                        \t|  1.8291e-06     \t|  1              \t|  1.8291e-06     \t|  1.4971e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_sanity_check_end                                                                              \t|  1.7919e-06     \t|  1              \t|  1.7919e-06     \t|  1.4666e-06     \t|\n",
      "|  [Callback]ModelPruning.on_fit_start                                                                                                                            \t|  1.777e-06      \t|  1              \t|  1.777e-06      \t|  1.4544e-06     \t|\n",
      "|  [Callback]EarlyStopping{'monitor': 'val/loss', 'mode': 'min'}.on_sanity_check_start                                                                            \t|  1.5944e-06     \t|  1              \t|  1.5944e-06     \t|  1.305e-06      \t|\n",
      "|  [Callback]ModelPruning.on_train_epoch_start                                                                                                                    \t|  1.5479e-06     \t|  1              \t|  1.5479e-06     \t|  1.2669e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  1.5385e-06     \t|  1              \t|  1.5385e-06     \t|  1.2593e-06     \t|\n",
      "|  [Callback]ModelPruning.on_sanity_check_end                                                                                                                     \t|  1.5255e-06     \t|  1              \t|  1.5255e-06     \t|  1.2486e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  1.5106e-06     \t|  1              \t|  1.5106e-06     \t|  1.2364e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                         \t|  1.505e-06      \t|  1              \t|  1.505e-06      \t|  1.2318e-06     \t|\n",
      "|  [Callback]ModelPruning.on_sanity_check_start                                                                                                                   \t|  1.4696e-06     \t|  1              \t|  1.4696e-06     \t|  1.2029e-06     \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model=litgpt, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLightningModule.load_from_checkpoint(\"/path/to/checkpoint.ckpt\")\n",
    "\n",
    "# disable randomness, dropout, etc...\n",
    "model.eval()\n",
    "\n",
    "# predict with the model\n",
    "y_hat = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this can be done with the DataModule as well but since we didn't want to make a dataloader for the test samples we use the manual method\n",
    "#already ran this one for this run\n",
    "def pad_left(sequence, final_length, padding_token):\n",
    "    return [padding_token] * (final_length - len(sequence)) + sequence\n",
    "\n",
    "class Generator:\n",
    "    def __init__(\n",
    "            self,\n",
    "            model,\n",
    "            tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def generate(\n",
    "            self,\n",
    "            max_tokens_to_generate: int,\n",
    "            prompt: str = None,\n",
    "            temperature: float = 1.0,\n",
    "            eos_token: int = None,\n",
    "            padding_token: int = config.eos_token_id):\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "        if prompt is None:\n",
    "            start_tokens = [config.eos_token_id]\n",
    "        else:\n",
    "            start_tokens = self.tokenizer.encode(prompt, allowed_special = \"all\")\n",
    "\n",
    "        input_tensor = torch.tensor(\n",
    "            pad_left(\n",
    "                sequence=start_tokens,\n",
    "                final_length=self.model.max_sequence_length + 1,\n",
    "                padding_token=padding_token\n",
    "            ),\n",
    "            dtype=torch.long\n",
    "        ).to(get_device())\n",
    "\n",
    "        num_dims = len(input_tensor.shape)\n",
    "\n",
    "        if num_dims == 1:\n",
    "            input_tensor = input_tensor[None, :]\n",
    "\n",
    "        out = input_tensor\n",
    "        for _ in range(max_tokens_to_generate):\n",
    "\n",
    "            x = out[:, -self.model.max_sequence_length:]\n",
    "\n",
    "            mask = torch.ones_like(x)\n",
    "            mask[x == padding_token] = 0\n",
    "\n",
    "            # Compute the next token probabilities\n",
    "            next_token_probabilities = self.model.next_token_probabilities(\n",
    "                x=x,\n",
    "                temperature=temperature,\n",
    "                mask=mask\n",
    "            )\n",
    "\n",
    "            # Sample the next token from the probability distribution\n",
    "            next_token = torch.multinomial(next_token_probabilities, num_samples=1)\n",
    "\n",
    "            # Append the next token to the output\n",
    "            out = torch.cat([out, next_token], dim=1)\n",
    "\n",
    "            # If the end of sequence token is reached, stop generating tokens\n",
    "            if eos_token is not None and next_token == eos_token:\n",
    "                break\n",
    "\n",
    "        generated_tokens = out[0].tolist()\n",
    "        return self.tokenizer.decode(generated_tokens)\n",
    "        #return ''.join([self.tokenizer.decode(token) for token in generated_tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "max_tokens_to_generate = 512\n",
    "generator = Generator(model, tokenizer)\n",
    "txt = \"\"\"\\\n",
    "# create some data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# create scatter plot with x, y\n",
    "\"\"\"\n",
    "generated_text = generator.generate(\n",
    "    max_tokens_to_generate=max_tokens_to_generate,\n",
    "    prompt=txt,\n",
    "    padding_token=eos_token_id\n",
    ")\n",
    "print(generated_text.replace(eos_token, ''))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "031f1eaa29104b169f5605519bc35a56": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03c00cb5f379473babd75bb9ec2ce777": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0ac6cb191c33445a9a500e76446b7440": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11255d5ac026403cab1f185d67171372": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a8218a010264caf813f82ad6ec81d80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1edddea06e354c859c693099fc59869a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88ed8bdd6b7445fd98f3dbf26694f2cb",
      "placeholder": "​",
      "style": "IPY_MODEL_1a8218a010264caf813f82ad6ec81d80",
      "value": " 26/26 [00:00&lt;00:00,  6.55it/s]"
     }
    },
    "211f72f39bd147c1b0e0758f312ac785": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "266fe7f780be46b7b7a786f45fc52f03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27c38b6b0cdf4bd9bd7534d697f310bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5069ebe6fa2f4183b0f135b46cad903c",
       "IPY_MODEL_9d3b56e986dd46c9bfc934c027623eb8",
       "IPY_MODEL_eb3232379f0f4cd1809f03864298e17e"
      ],
      "layout": "IPY_MODEL_d1b1db4883b9425885566349b3bfb771"
     }
    },
    "28038860cade426280e6357e725fddaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6e3a71b390ad46c2bbd49c2f3d882306",
      "max": 2980,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cad62726d05748468c76aa2bddfa7a9f",
      "value": 2980
     }
    },
    "2dcf5b137bf9429da393a22ba44a0690": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_031f1eaa29104b169f5605519bc35a56",
      "placeholder": "​",
      "style": "IPY_MODEL_eaf9670975bd45429ef727106f9acda7",
      "value": "Downloading readme: 100%"
     }
    },
    "351c18f3a6b14e8c9ca9d1a13a54eea4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41e85561fee74f0d852384eb79f7c047": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4736c709597142deb9dbebe94fc8958f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b9e87ed45054537aab741f0d0a96063": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5069ebe6fa2f4183b0f135b46cad903c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b0145647cf24b4fbda5bf3b793851f3",
      "placeholder": "​",
      "style": "IPY_MODEL_9125d7bfdaeb44d09b85edcae2ca2ac7",
      "value": "Generating train split: 100%"
     }
    },
    "5f91dc80894d4f3e9f8c8f3a46a19843": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "65617058a05a488c85cbcb2f121379b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6afcd33eed0144cd8b4b1bf31a034f09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6e3a71b390ad46c2bbd49c2f3d882306": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7de96955858d4aaaad54572761ddad06": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7eeed4f420ea4d7ea8bb75c1f8cc20be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2dcf5b137bf9429da393a22ba44a0690",
       "IPY_MODEL_28038860cade426280e6357e725fddaf",
       "IPY_MODEL_d51b79395f8d40cbb9e629537d1d8b39"
      ],
      "layout": "IPY_MODEL_266fe7f780be46b7b7a786f45fc52f03"
     }
    },
    "85897537871842abae7f77446a3e758e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88ed8bdd6b7445fd98f3dbf26694f2cb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fc4f8eaebd2499bbb89f88e2808bd88": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9125d7bfdaeb44d09b85edcae2ca2ac7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "93da4a3f85a946b79cdedbda5c249c5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b0145647cf24b4fbda5bf3b793851f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d3b56e986dd46c9bfc934c027623eb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0ac6cb191c33445a9a500e76446b7440",
      "max": 1415924,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5f91dc80894d4f3e9f8c8f3a46a19843",
      "value": 1415924
     }
    },
    "a081923d643541c2b8ebe5aeb1d3f5f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a457643427714397bcc326d75170d3eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ebee14caddbe4a73ac00fbbf55ffc949",
      "placeholder": "​",
      "style": "IPY_MODEL_4736c709597142deb9dbebe94fc8958f",
      "value": "Downloading data: 100%"
     }
    },
    "b61aadb89e5f489ea5584476311aa1bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7de96955858d4aaaad54572761ddad06",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41e85561fee74f0d852384eb79f7c047",
      "value": 26
     }
    },
    "b694f36cae4c4763a8a88322c0ad1fd0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb7f9592305f4a7bbfd823062d10035b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff5b94d367154134b9d51904d29e2645",
       "IPY_MODEL_f5f765b836894fb690176eb06af88df3",
       "IPY_MODEL_1edddea06e354c859c693099fc59869a"
      ],
      "layout": "IPY_MODEL_211f72f39bd147c1b0e0758f312ac785"
     }
    },
    "c33a18b4ec65446cb616ef6021856d99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b694f36cae4c4763a8a88322c0ad1fd0",
      "placeholder": "​",
      "style": "IPY_MODEL_4b9e87ed45054537aab741f0d0a96063",
      "value": " 26/26 [01:32&lt;00:00,  2.83s/files]"
     }
    },
    "cad62726d05748468c76aa2bddfa7a9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d1b1db4883b9425885566349b3bfb771": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d51b79395f8d40cbb9e629537d1d8b39": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_93da4a3f85a946b79cdedbda5c249c5c",
      "placeholder": "​",
      "style": "IPY_MODEL_351c18f3a6b14e8c9ca9d1a13a54eea4",
      "value": " 2.98k/2.98k [00:00&lt;00:00, 72.6kB/s]"
     }
    },
    "eaf9670975bd45429ef727106f9acda7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eb3232379f0f4cd1809f03864298e17e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8fc4f8eaebd2499bbb89f88e2808bd88",
      "placeholder": "​",
      "style": "IPY_MODEL_6afcd33eed0144cd8b4b1bf31a034f09",
      "value": " 1415924/1415924 [01:58&lt;00:00, 15916.05 examples/s]"
     }
    },
    "ebee14caddbe4a73ac00fbbf55ffc949": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f5f765b836894fb690176eb06af88df3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11255d5ac026403cab1f185d67171372",
      "max": 26,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_03c00cb5f379473babd75bb9ec2ce777",
      "value": 26
     }
    },
    "fa672fcdd4fa4c1f843277f3aa546f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a457643427714397bcc326d75170d3eb",
       "IPY_MODEL_b61aadb89e5f489ea5584476311aa1bf",
       "IPY_MODEL_c33a18b4ec65446cb616ef6021856d99"
      ],
      "layout": "IPY_MODEL_65617058a05a488c85cbcb2f121379b7"
     }
    },
    "ff5b94d367154134b9d51904d29e2645": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a081923d643541c2b8ebe5aeb1d3f5f7",
      "placeholder": "​",
      "style": "IPY_MODEL_85897537871842abae7f77446a3e758e",
      "value": "Resolving data files: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
